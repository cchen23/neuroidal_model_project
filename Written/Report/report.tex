\documentclass[letterpaper, 12pt]{article}

\usepackage[normalem]{ulem}
\usepackage{scrextend}	% for the indented environment
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{graphicx, caption, subcaption}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

% make everything 12pt font
\let\Huge\normalsize
\let\huge\normalsize
\let\LARGE\normalsize
\let\Large\normalsize
\let\large\normalsize
\let\small\normalsize
\let\footnotesize\normalsize
\let\scriptsize\normalsize
\let\tiny\normalsize

% Make everything single spacing
\linespread{1.0}

\begin{document}
%Header-Make sure you update this information!!!!
\noindent
\textbf{Study and Comparison of the Neuroidal Model} \hfill \newline Cathy Chen and Stefan Keselj \\
COS511 Final Project Report \\
Due May 15, 2018

\section{Introduction}
We studied the neuroidal model, a biologically plausible model of learning proposed by Valiant in 1994 \cite{valiant_circuits_1994}. In this report we present a concise summary of the model and abilities, based on Valiant's original book and subsequent work. We then study an extension proposed by Papadimitriou and Vempala, and describe the benefits of this extension \cite{papadimitriou_cortical_2015}. We select a few algorithms from these works to implement, and compare mechanisms of the neuroidal model to hypotheses about the human brain and to modern artificial neural networks.

\section{Neuroidal Model}\label{sec:model}
In this section we summarize our understanding of the neuroidal model. Our understanding primarily draws from \cite{valiant_circuits_1994, valiant_memorization_2005, papadimitriou_cortical_2015}.

The neuroidal model consists of a system of \underline{neurons} and \underline{synapses} which can be modeled as a weighted directed graph in which nodes represent neurons and edges represent synapses. Each neuron $i$ has a state $s_i$ containing three variables: a threshold $T\in\mathbb{R}_{>0}$, a categorical memory variable $q$, and an indicator variable $f$ that says whether the network is firing at that timestep. (In more complex versions of the model, $T\in\mathbb{R}^\gamma$, for $\gamma\in\mathbb{Z}$, which allows each neuron to store more information.) The synapse from neuron $i$ to neuron $j$ is represented by $w_{ji}\in W$, where $W$ may be a set such as $\mathbb{R}$ or $\{0,1\}$. In some versions of the model, each synapse also contains a memory state $qq$.

Each conceptual ``item" is represented by a group of $r$ neurons. The firing of an item's neurons denotes that the activation of the item (in terms of cognition, this means the system is ``thinking about" this item). 

The system operates with discrete timesteps and all neuroid and synapse states update at each timestep according to predefined functions. This model uses \underline{vicinal} algorithms, meaning that these predefined functions are local: each neuron's update depends only on its own state, the firing of adjacent neurons, and the weights connecting the neuron and its neighbors. The functions have the form $s_{i,t+1}=\delta(s_{i,t},w_i)$, $w_{ji,t+1}=\lambda(s_i,w_i,w_{ji},f_j)$, where $w_i$ is the sum over all $w_{ki}$ for all firing neurons $k$. In particular, neuron firing spreads through synapses according to the following update rule: neuron $i$ fires if $w_i>T$. Once a neuron fires it stops firing after a pre-determined number of timesteps; in more complex models, a neuron may be blocked from firing again for a certain number of timesteps after firing.

In \cite{valiant_circuits_1994} Valiant describes four modes of learning that result from two dichotomies: one between memorization (storing explicitly provided or logically deduced information) and inductive learning (acquiring knowledge more general than the explicitly provided examples), and the other between supervised (learning from labeled examples) and unsupervised (learning from unlabeled examples) learning. Under these dichotomies, the example-based learning and PAC learning framework that we studied in COS511 fall into supervised inductive learning.

Using the neuroidal model, Valiant presents algorithms that perform all four modes of learning. He constructs algorithms that allow a neuroidal network to recognize an input after a single presentation (unsupervised memorization), associating two items (supervised memorization), learning functions of a particular class from examples (supervised inductive learning), and learning statistical correlations from item presentations (unsupervised inductive learning).

A learning system can use various \underline{peripherals} to perceive and attend to various items, store intermediate information, and organize the longer-scale timing needed in various algorithms. Valiant suggests that the combination of peripherals and of knowledge gained through memorization and inductive learning could allow for higher-level reasoning in a neuroidal model.

\section{Selected Algorithms}\label{sec:selected_algorithms}
Our study focused on the JOIN and LINK algorithms, which respectively implement unsupervised and supervised memorization (in terms of Valiant's dichotomies) and forming memories and associations (in terms of cognitive functions) \cite{valiant_circuits_1994, papadimitriou_cortical_2015}. In this section, we provide a high-level overview of these algorithms and our implementation of these two functions, as well as an extension of Valiant's work the proposed a new function.

We assume that networks have two modes, a ``learning" mode in which the network stores some knowledge, and an ``execution" mode in which neurons fire if their total incoming firing falls above some threshold. 

The JOIN algorithm learns a conjunction of two items ``$A$" and ``$B$". During the learning mode the network's representations of $A$ and $B$ fire, and the network creates a new item ``$C$" that represents the conjunction of $A$ and $B$. Then in the execution mode the network's representation of $C$ will fire whenever the network's representations of $A$ and $B$ fire. For instance, if $A$ represents that item ``ice" and $B$ represents the item ``cream" then JOIN($A$,$B$) could form a representation of the item ``ice cream", and seeing ``ice" and ``cream" together would activate the representation of the thought ``ice cream" (rather than the separate thoughts ``ice" and ``cream").

The LINK algorithm learns an association of two items ``$A$" and ``$B$". After storing LINK($A$,$B$) in the learning mode, the network will activate $B$ when $A$ is activated (in the execution mode). For instance, if $A$ represents the idea ``bell" and $B$ represents the idea ``food", then LINK($A$,$B$) would form an association of ``food" with ``bell".

We implement these algorithms according to specifics described in \cite{valiant_memorization_2005} and provide implementation and details in TODO: LINK/DESCRIPTION.
- visualization of neuron activity?\\
- simulations\\
- compare to bounds?\\
- bounds\\

\subsection{Extension by Papadimitriou and Vempala}\label{sec:pjoin}
Papadimitriou and Vempala \cite{papadimitriou_cortical_2015} extend Valiant's work, adding an additional PJOIN operation.
- motivation for operation\\
- concise description of PJOIN\\
- bounds?\\

\section{Comparison to Human Brains}
Valiant's original model respects constraints posed by the human brain, such as the sparsity of connections and speed of processing in the human brain, and his comparison to experimental data from a biological system validates the biological plausibility of the neuroidal model \cite{valiant_quantitative_2006}. In this section we compare in more detail the neuroidal model and current hypotheses about learning in the human brain, particularly with respect to memory.

- grandmother cell,  jennifer anniston cell \cite{quiroga_invariant_2005}.\\
- compare to hopfield nets?\\
- neurons/synapses/updates\\
- action potentials (threshold)\\
- memory (esp associative memory) coactivation, random initialization\\
- creation and execution\\
	- different modes of hippocampus\\

- pattern separation/sparse activation (mtl part 1)\\
- item recognition in perirhinal cortex % https://piazza-resources.s3.amazonaws.com/iyg3i7tq28t7nt/iz78zxzjdb38s/MTL_PART_TWO_2017_REVISED.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAJZDMPX3EN6BQWN6Q%2F20180509%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180509T001944Z&X-Amz-Expires=10800&X-Amz-SignedHeaders=host&X-Amz-Security-Token=FQoDYXdzEMj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDDXb%2FAIhvnnG4RNlFiK3A7wcfEeEN%2B8laZxFcFsojjJfa46YQ4UkSwWrnEk%2B9IWfpipzsoBL9F0tNM%2FlK%2FSu3mowSWz869pX%2FnZJGrYJBqn%2B6i4EI7Vw1thuc67kqNYGQOmznxfig9ekR2TP%2Blz2vmoxb771Dd23fMgO98JJex2OTVpkeiG7TrYFe6VCmTUM8nlGeXmxamCGGr%2F%2BGtfSn3nnnIpKJa02p%2BFw1fWEYIcMSAw1ngL9o25ll9161%2FFs7WOxUvThHsSuEYGoc1l0qzrlhVcfCU9EddlmbFerSX4xxfG1926wfntVTxNJu%2FqdjKM2%2FTcm%2B9qo0QgzWt83tsODIR14JacR8uwDW%2FUfOjomWJYbGkGXvOCLUR0aju%2BMRsmkwkhMAAuoS1UK%2ByvFBue50NXyvfSNKR5owNCz%2B70DoX0WqbsbuAO5iDdlx%2B3jebtAjPOmV366S5WW0nBDMF88VMMWid9Nb0VTl%2BDMzAlbF56rZDz0U2Mvoxf2E%2Bb39MQwBKTKXURqAVXQAv7PCKj1hweVAK0XCYU6JF39RARoapDjxkJEUn%2FSVKDddbGPi0Gn5WBWzS%2BxS%2FPQRJmnbzzH4UOvdoAo18rI1wU%3D&X-Amz-Signature=afa591a669c54b99660f738b80d21fb725f462c1a9449bb846dd4f0e9a4bf9bd

\section{Comparison to Neural Networks}
The neuroidal model shares many structural similarities with neural networks, yet recent literature surrounding this model has been much sparser than than that of neural networks. In this section we compare structural and functional facets of the two models.

- similarities in structure\\
- differences in structure\\
- benefits\\
	- more interpretable (explicitly designing algorithms)\\
- detriments\\
	- hard to use as a black box; need explicit algorithms\\

\section{Conclusion}
Rather than perform neurobiological studies or behavioral experiments, Valiant proposes a computational approach of building a system that performs the desired behavior using components inspired by biology \cite{valiant_circuits_1994}. With this approach, the neuroidal model differs from work with the brain and artificial neural networks.

Unlike studies of the brain that start from specific analyses of biological components, this approach uses computational constraints to limit the space of algorithms, and finds algorithms within this space that accomplishes desired functions.

Unlike artificial neural networks which learn algorithms that are generally hard to interpret, the neuroidal model requires designing ``explicit computational mechanisms" for ``explicitly defined and possibly multiple cognitive tasks"; the need for designing \textit{explicit} mechanisms and tasks makes the neuroidal model perhaps less useful (at least at its current state) for generally solving problems, a use for which artificial neural networks have received much attention in the past few years.

Though this provides a disadvantage in terms of engineering solutions to large-scale problems, the explicit nature of the neuroidal model serves as an advantage for forming scientific hypotheses about learning. The explicit structure of the model and algorithms make the neuroidal model amenable to analyses of system parameters and capacity bounds that we mention in Section \ref{sec:model}, and the explicit nature of algorithms that we describe and implement in Section \ref{sec:selected_algorithms} allows us to more directly map the capabilities of the neuroidal model to hypotheses about how learning occurs in the human brain.

\bibliographystyle{IEEEtranS}
\bibliography{COS511}

\end{document}
